{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18167\n",
      "18167\n",
      "[['i', 'love', 'you', '.'], ['i', 'miss', 'you', '.'], ['i', 'need', 'you', '.'], ['i', 'think', 'so', '.'], ['i', 'use', 'this', '.']]\n",
      "[['SOS', '我', '爱', '您', '。', 'EOS'], ['SOS', '我', '想', '念', '你', '。', 'EOS'], ['SOS', '我', '需', '要', '你', '。', 'EOS'], ['SOS', '我', '想', '是', '這', '樣', '的', '。', 'EOS'], ['SOS', '我', '使', '用', '这', '个', '。', 'EOS']]\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "file_path = './data/cmn.txt'\n",
    "START_TOKEN = 'SOS'\n",
    "END_TOKEN = 'EOS'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    total_lines = sum(1 for line in file)\n",
    "\n",
    "lines_to_read = int(1 * total_lines)\n",
    "\n",
    "random_lines = random.sample(range(total_lines), lines_to_read)\n",
    "\n",
    "en = []\n",
    "cn = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line_number, line in enumerate(file):\n",
    "        if line_number in random_lines:\n",
    "            line = line.strip().split('\\t')\n",
    "            en.append(word_tokenize(line[0].lower()))\n",
    "            cn.append([START_TOKEN] + word_tokenize(\" \".join([w for w in line[1]])) + [END_TOKEN])\n",
    "\n",
    "print(len(en))\n",
    "print(len(cn))\n",
    "\n",
    "print(en[201:206])\n",
    "print(cn[201:206])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_len = [len(s) for s in en]\n",
    "cn_len = [len(s) for s in cn]\n",
    "f, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].hist(en_len, bins = 10)\n",
    "axs[0].set(ylim=(0, 100))\n",
    "axs[1].hist(cn_len, bins = 10)\n",
    "axs[1].set(ylim=(0, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter sentences by max_sequence_length of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 32\n",
    "valid_en = []\n",
    "valid_cn = []\n",
    "for i in range(len(en)):\n",
    "    if len(en[i]) <= max_sequence_length and len(cn[i]) <= max_sequence_length:\n",
    "        valid_en.append(en[i])\n",
    "        valid_cn.append(cn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of en tokens 6022\n",
      "number of cn tokens 3354\n"
     ]
    }
   ],
   "source": [
    "en_all_tokens = []\n",
    "for en_sentence in valid_en:\n",
    "    for token in en_sentence:\n",
    "        en_all_tokens.append(token)\n",
    "\n",
    "en_token_counts = Counter(en_all_tokens)\n",
    "en_common_tokens = en_token_counts.most_common(10000)\n",
    "print(f\"number of en tokens {len(en_common_tokens)}\")\n",
    "en_token_dict = {token: index for index, (token, _) in enumerate(en_common_tokens)}\n",
    "en_token_dict['UNK'] = len(en_common_tokens)\n",
    "en_token_dict['PAD'] = len(en_common_tokens) + 1\n",
    "\n",
    "cn_all_tokens = []\n",
    "for cn_sentence in valid_cn:\n",
    "    for token in cn_sentence:\n",
    "        cn_all_tokens.append(token)\n",
    "\n",
    "cn_token_counts = Counter(cn_all_tokens)\n",
    "cn_common_tokens = cn_token_counts.most_common(10000)\n",
    "print(f\"number of cn tokens {len(cn_common_tokens)}\")\n",
    "cn_token_dict = {token: index for index, (token, _) in enumerate(cn_common_tokens)}\n",
    "cn_token_dict['UNK'] = len(cn_common_tokens)\n",
    "cn_token_dict['PAD'] = len(cn_common_tokens) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18153\n",
      "18153\n",
      "[tensor([   0, 1771,    2,    1, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "        3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "        3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355]), tensor([   0,    6,   33,    2,    1, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "        3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "        3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355]), tensor([   0,    6,   86,  397,    4,    2,    1, 3355, 3355, 3355, 3355, 3355,\n",
      "        3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "        3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355])]\n",
      "6023\n",
      "3355\n"
     ]
    }
   ],
   "source": [
    "en_tokenized = []\n",
    "for en_sentence in valid_en:\n",
    "    if len(en_sentence) < max_sequence_length:\n",
    "        en_sentence = en_sentence + ['PAD'] * (max_sequence_length - len(en_sentence))\n",
    "    en_tokenized.append(torch.tensor([en_token_dict.get(token, en_token_dict['UNK']) for token in en_sentence]))\n",
    "\n",
    "cn_tokenized = []\n",
    "for cn_sentence in valid_cn:\n",
    "    if len(cn_sentence) < max_sequence_length:\n",
    "        cn_sentence = cn_sentence + ['PAD'] * (max_sequence_length - len(cn_sentence))\n",
    "    cn_tokenized.append(torch.tensor([cn_token_dict.get(token, cn_token_dict['UNK']) for token in cn_sentence]))\n",
    "\n",
    "print(len(en_tokenized))\n",
    "print(len(cn_tokenized))\n",
    "print(cn_tokenized[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, en_tokenized_sentences, cn_tokenized_sentences):\n",
    "        self.en_tokenized = en_tokenized_sentences\n",
    "        self.cn_tokenized = cn_tokenized_sentences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.en_tokenized)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.en_tokenized[idx], self.cn_tokenized[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TokenizedDataset(en_tokenized, cn_tokenized)\n",
    "\n",
    "# Define the size of your train and test datasets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "test_size = len(dataset) - train_size  # 20% for testing\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for train and test datasets\n",
    "batch_size = 3\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   1,   49,  383,   60,    0, 6023, 6023, 6023, 6023, 6023, 6023, 6023,\n",
      "         6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023,\n",
      "         6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023],\n",
      "        [   7,   41,  151,   24,    1,   65,   32,  157,    6, 6023, 6023, 6023,\n",
      "         6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023,\n",
      "         6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023],\n",
      "        [   8,  177,    5,  218,  163,    0, 6023, 6023, 6023, 6023, 6023, 6023,\n",
      "         6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023,\n",
      "         6023, 6023, 6023, 6023, 6023, 6023, 6023, 6023]]), tensor([[   0,    3,  276,  624,   15,   49,    4,  132,   23,   20,    2,    1,\n",
      "         3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "         3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355],\n",
      "        [   0,   13,   31,   39,  416,  170,    9,    3,   10,  161,   85,    4,\n",
      "           46,   62,    1, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "         3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355],\n",
      "        [   0,    7,  500,    5,    8,  318,    4,  489,    2,    1, 3355, 3355,\n",
      "         3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355,\n",
      "         3355, 3355, 3355, 3355, 3355, 3355, 3355, 3355]])]\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(eng_batch, cn_batch, eng_pad_token, cn_pad_token):\n",
    "    # Create masks based on padding tokens\n",
    "    eng_mask = (eng_batch == eng_pad_token)\n",
    "    cn_mask = (cn_batch == cn_pad_token)\n",
    "\n",
    "    # Create Look-Ahead Mask\n",
    "    max_sequence_length = eng_batch.size(1)  # Assuming both batches have the same sequence length\n",
    "    look_ahead_mask = torch.triu(torch.ones(max_sequence_length, max_sequence_length), diagonal=1) == 1\n",
    "\n",
    "    # Expand masks to 3D for self-attention and cross-attention\n",
    "    encoder_padding_mask = eng_mask.unsqueeze(1).repeat(1, max_sequence_length, 1)\n",
    "    decoder_padding_mask_self_attention = cn_mask.unsqueeze(1).repeat(1, max_sequence_length, 1)\n",
    "    decoder_padding_mask_cross_attention = eng_mask.unsqueeze(1).repeat(1, max_sequence_length, 1)\n",
    "\n",
    "    # Calculate the final masks with some negative infinity value for masked positions\n",
    "    NEG_INFTY = -1e9\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask = torch.where(look_ahead_mask.unsqueeze(0) + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pad_token = en_token_dict.get('PAD')\n",
    "cn_pad_token = cn_token_dict.get('PAD')\n",
    "# Assuming eng_batch and cn_batch are your input tensors\n",
    "encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(first_batch[0], first_batch[1], eng_pad_token, cn_pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
      "        -1.0000e+09, -1.0000e+09])\n"
     ]
    }
   ],
   "source": [
    "print(decoder_cross_attention_mask[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if item is Chinese character\n",
    "# cn_end_marks_filtered = []\n",
    "# for item in cn_end_marks_set:\n",
    "#     if not re.search(\"[\\u4e00-\\u9FFF]\", item):\n",
    "#         cn_end_marks_filtered.append(item)\n",
    "# print(cn_end_marks_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "eng_batch = torch.tensor([[23, 7, 5, 1, 1], [15, 25, 2, 6, 1]])\n",
    "cn_batch = torch. tensor([[6, 8, 1, 1, 1], [19, 5, 3, 1, 1]])\n",
    "padding_token = 1\n",
    "eng_mask = (eng_batch == padding_token)\n",
    "cn_mask = (cn_batch == padding_token)\n",
    "decoder_padding_mask_self_attention = cn_mask.unsqueeze(1).repeat(1, 5, 1)\n",
    "print(decoder_padding_mask_self_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look ahead mask:\n",
      " tensor([[False,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False, False]])\n",
      "tensor([[[False,  True,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True]],\n",
      "\n",
      "        [[False,  True,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "look_ahead_mask = torch.triu(torch.ones(5, 5), diagonal=1) == 1\n",
    "print(f\"look ahead mask:\\n {look_ahead_mask}\")\n",
    "decoder_padding_mask_cross_attention = look_ahead_mask.unsqueeze(0) + decoder_padding_mask_self_attention\n",
    "print(decoder_padding_mask_cross_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
      "\n",
      "        [[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09]]])\n"
     ]
    }
   ],
   "source": [
    "decoder_cross_attention_mask = torch.where((decoder_padding_mask_cross_attention), NEG_INFTY, 0)\n",
    "print(decoder_cross_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
